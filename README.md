# ğŸ¤– ArXiv Multi-Agent Research Assistant

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![React](https://img.shields.io/badge/react-18-cyan)
![FastAPI](https://img.shields.io/badge/fastapi-0.109-green)
![Docker](https://img.shields.io/badge/docker-ready-blue)
![Ollama](https://img.shields.io/badge/AI-Ollama-orange)

An intelligent, local-first academic research assistant powered by **Multi-Agent Systems** and **Local LLMs**. It automates the workflow of discovering, parsing, and summarizing ArXiv papers, presented in a modern, dark-mode enabled web interface.

---

## âœ¨ Key Features

* **ğŸ•µï¸ Multi-Agent Workflow**: Automated pipeline involving Scraper, Parser, Vector Embedding, Summarizer, and Reviewer agents.
* **ğŸ§  Local Intelligence**: Uses **Ollama (Llama 3)** for privacy-preserving, cost-free summarization. No API keys required.
* **ğŸ’¬ Insight-First Chat**: Interactive chat with **Guided Questions** and **Deep Insight Reports** generated by a specialized Reviewer Agent.
* **ğŸ” RAG-Powered Insights**: Retrieves relevant context from full PDF texts to generate accurate academic summaries.
* **ğŸ’» Modern UI**: Responsive React frontend with **Google-style search**, stacked card layout, and smooth animations.
* **ğŸ³ Dockerized**: Easy deployment with full stack Docker support.

---

## ğŸ—ï¸ System Architecture

The system follows a **Headless Architecture** separating the Python backend agents from the React frontend.

| Component | Technology | Description |
| :--- | :--- | :--- |
| **Frontend** | React + Vite + Tailwind | Interactive dashboard for searching, chatting, and viewing summaries. |
| **Backend API** | FastAPI | RESTful API to orchestrate agents and serve data. |
| **Reviewer Agent** | `Ollama` (JSON Mode) | Generates structured critiques and suggested questions. |
| **Scraper/Parser** | `arxiv` / `PyMuPDF` | Fetches metadata and extracts text from PDFs. |
| **Vector Agent** | `FAISS` | Creates vector embeddings for semantic search (RAG). |

---

## ğŸš€ Quick Start (Docker Recommended)

*Best for users who want to try the app immediately without installing local dependencies.*

### Prerequisites
* **Docker Desktop** installed and running.
* **Ollama** installed on your host machine and running (`ollama serve`).
* **Pull Model**: Run `ollama pull llama3.2` (or the model defined in `config.yaml`).

### Setup & Run

1. **Clone the repository**
   ```bash
   git clone [https://github.com/z0n6/arxiv-agent.git](https://github.com/z0n6/arxiv-agent.git)
   cd arxiv-agent
````

2.  **Environment Configuration**
    Copy the example configuration file:

    ```bash
    cp .env.example .env
    ```

    *(Optional)* Edit `.env` if you need to change the default ports (Frontend: 5173, Backend: 8001).

3.  **Start the Application**

    ```bash
    docker-compose up --build
    ```

4.  **Access**
    Open your browser and go to: `http://localhost:5173` (or the port defined in `.env`).

### âš ï¸ Troubleshooting Docker

  * **Ollama Connection**: The backend connects to Ollama via `host.docker.internal`.
  * **Linux Users**: If you are on Linux, you might need to launch Ollama with:
    `OLLAMA_HOST=0.0.0.0 ollama serve` to allow container access.

-----

## ğŸ› ï¸ Development Setup (Manual)

*Best for developers who want to modify code or debug.*

### 1. Configuration

Create a `.env` file in the root directory:

```bash
cp .env.example .env
```

### 2. Backend Setup

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Start the Backend Server
python src/api.py
```

### 3. Frontend Setup

Open a new terminal window:

```bash
cd frontend
npm install
npm run dev
```

-----

## ğŸ“– Usage Guide

1.  **Fetch Data**: Click the **"Fetch Papers"** button. The system scrapes papers based on keywords in `config.yaml`.
2.  **Search & Filter**: Use the search bar or filter by category (e.g., *Computer Vision*) and time.
3.  **Review & Chat**: Click **"Ask AI"** on any paper card.
      * The **Reviewer Agent** will first generate a deep insight report (TL;DR, Pros/Cons).
      * Use the **Suggested Question** chips to dive deeper.
4.  **Dark Mode**: Toggle the moon/sun icon in the header.

-----

## âš™ï¸  Configuration

Customize agent behavior in `config.yaml`:

```yaml
scraper:
  keywords: ["Multi-Agent Systems", "LLM", "Generative AI"]
  max_results: 10

summarizer:
  model_name: "llama3.2" # Model for general summarization

reviewer:
  model_name: "llama3.2" # Model for critiques and chat (can use a larger model like llama3:8b)
```

-----

## ğŸ“‚ Project Structure

```text
arxiv-agent/
â”œâ”€â”€ config.yaml              # Global configuration
â”œâ”€â”€ docker-compose.yml       # Docker orchestration
â”œâ”€â”€ .env.example             # Environment variables template
â”œâ”€â”€ data/                    # PDF storage & Metadata DB
â”œâ”€â”€ frontend/                # React Source Code
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib/api.js       # Centralized API client
â”‚   â”‚   â””â”€â”€ components/      # UI Components (ChatModal, etc.)
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ src/                     # Python Backend Source
â”‚   â”œâ”€â”€ agents/              # Multi-Agent Logic (Scraper, Reviewer, Chat, etc.)
â”‚   â””â”€â”€ api.py               # FastAPI Entry Point
â””â”€â”€ Dockerfile.backend       # Backend Dockerfile
```

-----

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

-----

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.
