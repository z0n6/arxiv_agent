import os
import json
import yaml
import ollama
from loguru import logger
from typing import Dict, Any, List

# å¼•å…¥ VectorAgent ä»¥ä¾¿é€²è¡Œ RAG æª¢ç´¢
from agents.vector_agent import VectorAgent

class SummarizerAgent:
    def __init__(self, config_path: str = "config.yaml"):
        self.config = self._load_config(config_path)
        self.data_dir = self.config['data']['output_dir']
        self.metadata_path = os.path.join(self.data_dir, self.config['data']['metadata_file'])
        
        # åˆå§‹åŒ– Vector Agent ç”¨æ–¼æª¢ç´¢
        self.vector_agent = VectorAgent(config_path)
        
        self.model = self.config['summarizer']['model_name']
        logger.info(f"ğŸ“ Summarizer Agent initialized using model: {self.model}")

    def _load_config(self, path: str) -> Dict[str, Any]:
        with open(path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _load_metadata(self) -> List[Dict]:
        if not os.path.exists(self.metadata_path):
            return []
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def generate_summary(self, paper_id: str, mode: str = "quick_summary") -> str:
        """ç”ŸæˆæŒ‡å®šè«–æ–‡çš„æ‘˜è¦"""
        
        # 1. ç²å–åŸºæœ¬è³‡è¨Š
        papers = self._load_metadata()
        target_paper = next((p for p in papers if p['id'] == paper_id), None)
        
        if not target_paper:
            logger.error(f"âŒ Paper ID {paper_id} not found.")
            return "Error: Paper not found."

        title = target_paper['title']
        abstract = target_paper['summary']
        
        # 2. RAG æª¢ç´¢ï¼šæ‰¾å‡ºé€™ç¯‡è«–æ–‡ä¸­é—œæ–¼ "methodology" å’Œ "conclusion" çš„ç‰‡æ®µ
        # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘ç°¡å–®åœ°ç”¨æ¨™é¡Œ+é—œéµå­—å»æœï¼Œå¯¦éš›æ‡‰ç”¨å¯èƒ½éœ€è¦ filter by paper_id (FAISS é€²éšç”¨æ³•)
        # ç‚ºç°¡åŒ–åŸå‹ï¼Œæˆ‘å€‘å…ˆå‡è¨­æœå°‹åˆ°çš„å…§å®¹å¤§éƒ¨åˆ†ç›¸é—œï¼Œæˆ–è€…åƒ…ä½¿ç”¨ Abstract + å‰å¹¾å€‹ Chunk
        
        # ç­–ç•¥ï¼šçµ„åˆ Abstract + æ„æœå°‹åˆ°çš„è£œå……è³‡è¨Š
        context_query = f"{title} methodology and conclusion"
        rag_results = self.vector_agent.search(context_query, top_k=3)
        rag_text = "\n".join([res['text'] for res in rag_results])
        
        # 3. æ§‹å»º Prompt
        # çµ„åˆå…§å®¹ï¼šæ¨™é¡Œ + æ‘˜è¦ + RAG æª¢ç´¢åˆ°çš„å…§æ–‡
        full_context = f"Title: {title}\nAbstract: {abstract}\nKey Excerpts:\n{rag_text}"
        
        # è®€å–æ¨¡æ¿
        prompt_template = self.config['summarizer']['prompts'][mode]
        system_prompt = self.config['summarizer']['system_prompt']
        
        user_message = prompt_template.format(text=full_context)

        logger.info(f"ğŸ¤– Sending request to Ollama ({mode})...")

        # 4. å‘¼å« Ollama
        try:
            response = ollama.chat(model=self.model, messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_message},
            ])
            
            return response['message']['content']
            
        except Exception as e:
            logger.error(f"âŒ Ollama generation failed: {e}")
            return f"Generation Error: {e}"

if __name__ == "__main__":
    # æ¸¬è©¦ç”¨ï¼šç›´æ¥è·‘ç¬¬ä¸€ç¯‡è«–æ–‡
    agent = SummarizerAgent()
    papers = agent._load_metadata()
    if papers:
        first_paper_id = papers[0]['id']
        print(f"Summarizing Paper: {first_paper_id}...")
        summary = agent.generate_summary(first_paper_id, mode="quick_summary")
        print("\n=== Summary Result ===\n")
        print(summary)
