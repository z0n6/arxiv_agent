import streamlit as st
import os
import json
import yaml
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components
from datetime import datetime

# å¼•å…¥ Agents
from agents.scraper_agent import ScraperAgent
from agents.parser_agent import ParserAgent
from agents.vector_agent import VectorAgent
from agents.summarizer_agent import SummarizerAgent

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="ArXiv Agent",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ---------------------------------------------------------
# 1. è³‡æºå¿«å– (é¿å…æ¯æ¬¡æŒ‰æŒ‰éˆ•éƒ½é‡è¼‰æ¨¡å‹)
# ---------------------------------------------------------
@st.cache_resource
def load_agents():
    # é€™è£¡åªåˆå§‹åŒ–ä¸éœ€è¦é‡ç½®ç‹€æ…‹çš„ Agent
    # Scraper å’Œ Parser é€šå¸¸æ˜¯æŒ‰éœ€åŸ·è¡Œï¼Œä¸éœ€å¿«å–
    vector_agent = VectorAgent() # æœƒè¼‰å…¥ Embedding æ¨¡å‹
    summarizer_agent = SummarizerAgent() # æœƒé€£æ¥ Ollama
    return vector_agent, summarizer_agent

# è¼‰å…¥è¨­å®šæª”
def load_config():
    with open("config.yaml", "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

config = load_config()
vector_agent, summarizer_agent = load_agents()

# ---------------------------------------------------------
# 2. å´é‚Šæ¬„ (Sidebar): æ§åˆ¶èˆ‡éæ¿¾
# ---------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ æ§åˆ¶å°")
    
    st.subheader("1. æ•¸æ“šæ›´æ–°")
    if st.button("ğŸš€ åŸ·è¡Œå®Œæ•´æµç¨‹ (Scrape -> Parse -> Vector)"):
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            # Step 1: Scrape
            status_text.text("ğŸ•µï¸ æ­£åœ¨æŠ“å– ArXiv...")
            scraper = ScraperAgent()
            scraper.run()
            progress_bar.progress(33)
            
            # Step 2: Parse
            status_text.text("ğŸ”¬ æ­£åœ¨è§£æ PDF...")
            parser = ParserAgent()
            parser.run()
            progress_bar.progress(66)
            
            # Step 3: Vector
            status_text.text("ğŸ§  æ­£åœ¨æ›´æ–°å‘é‡ç´¢å¼•...")
            vector_agent.create_index()
            progress_bar.progress(100)
            
            status_text.text("âœ… æ›´æ–°å®Œæˆï¼")
            st.success("æ‰€æœ‰è³‡æ–™å·²æ›´æ–°ï¼Œè«‹åˆ·æ–°é é¢ã€‚")
            st.cache_data.clear() # æ¸…é™¤æ•¸æ“šå¿«å–
            
        except Exception as e:
            st.error(f"åŸ·è¡Œå¤±æ•—: {e}")

    st.divider()
    st.subheader("2. é¡¯ç¤ºè¨­å®š")
    show_graph = st.toggle("é¡¯ç¤ºé—œè¯åœ–", value=True)

# ---------------------------------------------------------
# 3. ä¸»ç•«é¢ (Main Area)
# ---------------------------------------------------------
st.title(config['reporter']['app_title'])
st.markdown("åŸºæ–¼ **Local LLM** èˆ‡ **Multi-Agent** çš„å­¸è¡“è«–æ–‡åŠ©ç†")

# è®€å–è³‡æ–™
metadata_path = os.path.join(config['data']['output_dir'], config['data']['metadata_file'])
if os.path.exists(metadata_path):
    with open(metadata_path, 'r', encoding='utf-8') as f:
        papers = json.load(f)
        # æŒ‰æ—¥æœŸå€’åº
        papers.reverse()
else:
    papers = []
    st.warning("å°šæœªæœ‰è³‡æ–™ï¼Œè«‹é»æ“Šå´é‚Šæ¬„çš„ã€ŒåŸ·è¡Œå®Œæ•´æµç¨‹ã€ã€‚")

# Tab åˆ†é è¨­è¨ˆ
tab1, tab2 = st.tabs(["ğŸ“š è«–æ–‡åˆ—è¡¨èˆ‡æ‘˜è¦", "ğŸ•¸ï¸ çŸ¥è­˜é—œè¯åœ–"])

# === Tab 1: è«–æ–‡åˆ—è¡¨ ===
with tab1:
    col1, col2 = st.columns([1, 3])
    with col1:
        st.metric("å·²æ”¶éŒ„è«–æ–‡", len(papers))
    
    st.divider()

    for paper in papers:
        with st.expander(f"ğŸ“„ {paper['title']} ({paper['id']})"):
            c1, c2 = st.columns([2, 1])
            
            with c1:
                st.markdown(f"**ä½œè€…**: {', '.join(paper['authors'])}")
                st.markdown(f"**ç™¼å¸ƒæ—¥æœŸ**: {paper['published']}")
                st.info(f"**Abstract**: {paper['summary']}")
                
                # ä¸‹è¼‰/é–‹å•Ÿ PDF é€£çµ
                st.markdown(f"[ğŸ“¥ é–‹å•ŸåŸå§‹ PDF]({paper['pdf_url']})")

            with c2:
                st.subheader("ğŸ“ AI æ‘˜è¦")
                
                # ç‚ºæ¯ç¯‡è«–æ–‡ç”¢ç”Ÿå”¯ä¸€çš„ key
                btn_key = f"btn_{paper['id']}"
                summary_key = f"summary_{paper['id']}"
                
                # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„æ‘˜è¦å­˜åœ¨ Session State
                if summary_key not in st.session_state:
                    if st.button("âœ¨ ç”Ÿæˆæ‘˜è¦", key=btn_key):
                        with st.spinner("æ­£åœ¨é–±è®€ä¸¦ç”Ÿæˆæ‘˜è¦..."):
                            summary = summarizer_agent.generate_summary(paper['id'], mode="quick_summary")
                            st.session_state[summary_key] = summary
                            st.rerun() # é‡æ–°æ¸²æŸ“ä»¥é¡¯ç¤ºçµæœ
                
                if summary_key in st.session_state:
                    st.success("ç”Ÿæˆå®Œæˆï¼")
                    st.markdown(st.session_state[summary_key])
                    if st.button("ğŸ—‘ï¸ æ¸…é™¤", key=f"clr_{paper['id']}"):
                        del st.session_state[summary_key]
                        st.rerun()

# === Tab 2: çŸ¥è­˜é—œè¯åœ– ===
with tab2:
    if show_graph and papers:
        st.subheader("ä½œè€…èˆ‡è«–æ–‡é—œè¯åœ–")
        
        # å»ºç«‹ç°¡å–®çš„ç¶²è·¯åœ–ï¼šè«–æ–‡ <-> ä½œè€…
        G = nx.Graph()
        
        for paper in papers[:10]: # ç‚ºäº†æ•ˆèƒ½ï¼Œåªç•«å‰10ç¯‡
            paper_node = paper['id']
            G.add_node(paper_node, label=paper['title'][:20]+"...", title=paper['title'], color="#FF4B4B", shape="box")
            
            for author in paper['authors']:
                G.add_node(author, label=author, title=author, color="#0083B8")
                G.add_edge(paper_node, author)

        # ä½¿ç”¨ PyVis è¦–è¦ºåŒ–
        net = Network(height="500px", width="100%", bgcolor="#ffffff", font_color="black")
        net.from_nx(G)
        
        # å­˜æˆè‡¨æ™‚ HTML ä¸¦è®€å–
        path = "tmp_graph.html"
        net.save_graph(path)
        
        with open(path, 'r', encoding='utf-8') as f:
            html_source = f.read()
            components.html(html_source, height=500)
        
        st.caption("ç´…è‰²æ–¹å¡Šï¼šè«–æ–‡ | è—è‰²åœ“é»ï¼šä½œè€…")
    elif not papers:
        st.info("ç„¡è³‡æ–™å¯ç¹ªè£½ã€‚")
